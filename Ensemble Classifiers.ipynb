{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done getting train/test sets\n",
      "getting images from paths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pdb as pdb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "settings = {\n",
    "    'minNeighbors': 2, \n",
    "    'minSize': (40,40)\n",
    "}\n",
    "image_list = pd.read_csv('driver_imgs_list.csv')\n",
    "train_subject_subset = image_list.subject.value_counts()[-9:].index.values\n",
    "test_subject_subset = image_list.subject.value_counts()[:-9].index.values\n",
    "train = image_list[image_list.subject.isin(train_subject_subset)].reset_index(drop=True)\n",
    "test = image_list[image_list.subject.isin(test_subject_subset)].reset_index(drop=True)\n",
    "\n",
    "#take 25% of the sets \n",
    "mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "train = train[mask]\n",
    "mask = np.random.choice([False, True], len(test), p=[0.75, 0.25])\n",
    "test = test[mask]\n",
    "print 'done getting train/test sets'\n",
    "print 'getting images from paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "predict_images = []\n",
    "labels = [] \n",
    "predict_labels = []\n",
    "\n",
    "t0 = time.time()\n",
    "scaled_size = (200,150)\n",
    "\n",
    "for i, image in train.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    images.append(image.flatten())\n",
    "    labels.append(train['classname'][i])\n",
    "    \n",
    "for i, image in test.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    predict_images.append(predict_image.flatten())\n",
    "    predict_labels.append(test['classname'][i])\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5045.3704741s\n",
      "training classifier\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant data\n",
    "training_data = images\n",
    "training_labels = labels\n",
    "prediction_data = predict_images\n",
    "prediction_labels = predict_labels\n",
    "\n",
    "training_labels = map(lambda each:int(each.strip(\"c\")), training_labels)\n",
    "prediction_labels = map(lambda each:int(each.strip(\"c\")), prediction_labels)\n",
    "\n",
    "training_data = map(lambda each:each.flatten(), training_data)\n",
    "prediction_data = map(lambda each:each.flatten(), prediction_data)\n",
    "\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "print (\"training classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using GradientBoostingClassifier: 686 / 4085 %\n",
      "done in 5633.85348105s\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using GradientBoostingClassifier: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {}s\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using RandomForestClassifier: 919 / 4085 %\n",
      "done in 1507.87428212s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using RandomForestClassifier: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {}s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using ExtraTreesClassifier: 1173 / 4085 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=500, max_depth=None, \n",
    "                           min_samples_split=2, random_state=0,n_jobs=-1,warm_start=True)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using ExtraTreesClassifier: {} / {} %'.format(correct, len(prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using DecisionTreeClassifier: 622 / 4085 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using DecisionTreeClassifier: {} / {} %'.format(correct, len(prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'warm_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ff40253cb61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,learning_rate=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprediction_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'warm_start'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=500,random_state=0,warm_start=True)#,learning_rate=)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using AdaBoostClassifier: {} / {} %'.format(correct, len(prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using LabelPropagation: 480 / 4085 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/semi_supervised/label_propagation.py:198: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "clf = LabelPropagation(kernel='rbf', gamma=20, n_neighbors=7, \n",
    "                       alpha=1, max_iter=30, tol=0.001, n_jobs=-1)#,learning_rate=)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using LabelPropagation: {} / {} %'.format(correct, len(prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using BaggingClassifier: 751 / 4085 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf = BaggingClassifier(n_estimators=500, warm_start=True, n_jobs=-1)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using BaggingClassifier: {} / {} %'.format(correct, len(prediction_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pdb.set_trace()\n",
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# for i, image in enumerate(prediction_data):\n",
    "#     pred = OneVsOneClassifier(clf.predict(image))\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using SVM one vs one: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "# print (\"making predictions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# pred = OneVsOneClassifier(clf.predict(prediction_data))\n",
    "\n",
    "# correct = np.sum(pred == prediction_labels)\n",
    "\n",
    "# print 'accuracy using SVM one vs one: {}%'.format((100*correct)/len(prediction_labels))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "# print (\"making predictions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# for i, image in enumerate(prediction_data):\n",
    "#     pred = OneVsRestClassifier(clf.predict(image))\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using SVM one vs rest: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
