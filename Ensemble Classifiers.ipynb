{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done getting train/test sets\n",
      "getting images from paths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pdb as pdb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "settings = {\n",
    "    'minNeighbors': 2, \n",
    "    'minSize': (40,40)\n",
    "}\n",
    "image_list = pd.read_csv('driver_imgs_list.csv')\n",
    "train_subject_subset = image_list.subject.value_counts()[-9:].index.values\n",
    "test_subject_subset = image_list.subject.value_counts()[:-9].index.values\n",
    "train = image_list[image_list.subject.isin(train_subject_subset)].reset_index(drop=True)\n",
    "test = image_list[image_list.subject.isin(test_subject_subset)].reset_index(drop=True)\n",
    "\n",
    "#take 25% of the sets \n",
    "mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "train = train[mask]\n",
    "mask = np.random.choice([False, True], len(test), p=[0.75, 0.25])\n",
    "test = test[mask]\n",
    "print 'done getting train/test sets'\n",
    "print 'getting images from paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "predict_images = []\n",
    "labels = [] \n",
    "predict_labels = []\n",
    "\n",
    "t0 = time.time()\n",
    "scaled_size = (200,150)\n",
    "\n",
    "for i, image in train.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    images.append(image.flatten())\n",
    "    labels.append(train['classname'][i])\n",
    "    \n",
    "for i, image in test.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    predict_images.append(predict_image.flatten())\n",
    "    predict_labels.append(test['classname'][i])\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 82.0683870316s\n",
      "training classifier\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant data\n",
    "training_data = images\n",
    "training_labels = labels\n",
    "prediction_data = predict_images\n",
    "prediction_labels = predict_labels\n",
    "\n",
    "training_labels = map(lambda each:int(each.strip(\"c\")), training_labels)\n",
    "prediction_labels = map(lambda each:int(each.strip(\"c\")), prediction_labels)\n",
    "\n",
    "training_data = map(lambda each:each.flatten(), training_data)\n",
    "prediction_data = map(lambda each:each.flatten(), prediction_data)\n",
    "\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "print (\"training classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(training_data, training_labels)\n",
    "score = clf.score(prediction_data, prediction_labels)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "score = clf.score(prediction_data, prediction_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "score = clf.score(prediction_data, prediction_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf = clf.fit(training_data, training_labels)\n",
    "score = clf.score(prediction_data, prediction_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pdb.set_trace()\n",
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# for i, image in enumerate(prediction_data):\n",
    "#     pred = OneVsOneClassifier(clf.predict(image))\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using SVM one vs one: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "# print (\"making predictions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# pred = OneVsOneClassifier(clf.predict(prediction_data))\n",
    "\n",
    "# correct = np.sum(pred == prediction_labels)\n",
    "\n",
    "# print 'accuracy using SVM one vs one: {}%'.format((100*correct)/len(prediction_labels))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "# print (\"making predictions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0\n",
    "# for i, image in enumerate(prediction_data):\n",
    "#     pred = OneVsRestClassifier(clf.predict(image))\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using SVM one vs rest: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
