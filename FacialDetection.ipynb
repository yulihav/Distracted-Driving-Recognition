{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done getting train/test sets \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pdb as pdb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "# Different recognizers\n",
    "recognizer_LBPH = cv2.face.createLBPHFaceRecognizer()\n",
    "recognizer_Fisher = cv2.face.createFisherFaceRecognizer()\n",
    "recognizer_Eigen = cv2.face.createEigenFaceRecognizer()\n",
    "\n",
    "# haar cascades for recognizing different angles\n",
    "cascade_paths = ['haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_default.xml', 'haarcascade_profileface.xml']\n",
    "\n",
    "face_alt = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "face_default = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "face_profile = cv2.CascadeClassifier(\"haarcascade_profileface.xml\")\n",
    "\n",
    "settings = {\n",
    "    'minNeighbors': 2, \n",
    "    'minSize': (40,40)\n",
    "}\n",
    "\n",
    "\n",
    "# train = pd.read_csv('driver_imgs_list.csv')\n",
    "# mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "# train = train[mask]\n",
    "# #train = train[0:500]\n",
    "image_list = pd.read_csv('driver_imgs_list.csv')\n",
    "train_subject_subset = image_list.subject.value_counts()[-9:].index.values\n",
    "test_subject_subset = image_list.subject.value_counts()[:-9].index.values\n",
    "train = image_list[image_list.subject.isin(train_subject_subset)].reset_index(drop=True)\n",
    "test = image_list[image_list.subject.isin(test_subject_subset)].reset_index(drop=True)\n",
    "\n",
    "mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "train = train[mask]\n",
    "mask = np.random.choice([False, True], len(test), p=[0.75, 0.25])\n",
    "test = test[mask]\n",
    "print 'done getting train/test sets '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting images from paths\n"
     ]
    }
   ],
   "source": [
    "print 'getting images from paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 62.6993808746s\n"
     ]
    }
   ],
   "source": [
    "# predict_images = []\n",
    "# t0 = time.time()\n",
    "# scaled_size = (200,150)\n",
    "# for i, image in train.iterrows():\n",
    "#     image_path = './train/' + image.classname + '/' + image.img\n",
    "#     predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "#     #predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "#     predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "#     predict_images.append(predict_image)\n",
    "    \n",
    "# images, predict_images, labels, predict_labels = train_test_split( predict_images, train['classname'], test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "\n",
    "images = []\n",
    "predict_images = []\n",
    "labels = [] \n",
    "predict_labels = []\n",
    "\n",
    "t0 = time.time()\n",
    "scaled_size = (200,150)\n",
    "\n",
    "for i, image in train.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    #predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    images.append(image)\n",
    "    labels.append(train['classname'][i])\n",
    "    \n",
    "for i, image in test.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    #predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    predict_images.append(predict_image)\n",
    "    predict_labels.append(test['classname'][i])\n",
    "    \n",
    "#images, predict_images, labels, predict_labels = train_test_split( predict_images, train['classname'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting faces from training data\n"
     ]
    }
   ],
   "source": [
    "print 'detecting faces from training data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 761 faces, out of 1535 (0.50)\n",
      "done in 171.261979103s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract relevant data\n",
    "training_data = images\n",
    "training_labels = labels\n",
    "prediction_data = predict_images\n",
    "prediction_labels = predict_labels\n",
    "\n",
    "training_labels = map(lambda each:int(each.strip(\"c\")), training_labels)\n",
    "prediction_labels = map(lambda each:int(each.strip(\"c\")), prediction_labels)\n",
    "\n",
    "train_X=[]\n",
    "train_Y=[]\n",
    "test_X=[]\n",
    "test_Y=[]\n",
    "\n",
    "num_detect = 0\n",
    "num_not_detect = 0\n",
    "\n",
    "t0 = time.time()\n",
    "for j, image in enumerate(training_data):\n",
    "\n",
    "    #detect using different classifiers\n",
    "    face = face_alt.detectMultiScale(image, **settings)\n",
    "    face2 = face_default.detectMultiScale(image, **settings)\n",
    "    face3 = face_profile.detectMultiScale(image, **settings)\n",
    "\n",
    "    #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face2) == 1:\n",
    "        facefeatures = face2\n",
    "    elif len(face3) == 1:\n",
    "        facefeatures = face3\n",
    "    else:\n",
    "        facefeatures = \"\"\n",
    "        num_not_detect = num_not_detect + 1\n",
    "\n",
    "    for (x, y, w, h) in facefeatures:\n",
    "        num_detect = num_detect + 1\n",
    "        train_X.append(image[y: y + h, x: x + w])\n",
    "        train_Y.append(training_labels[j])\n",
    "        cv2.imshow(\"Adding faces to traning set...\", image[y: y + h, x: x + w])\n",
    "        #cv2.waitKey(100)\n",
    "\n",
    "percentage = num_detect/float((num_detect + num_not_detect))\n",
    "print 'detected {} faces, out of {} ({:0.2f})'.format(num_detect, num_detect + num_not_detect, percentage)\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using LBPH\n"
     ]
    }
   ],
   "source": [
    "print 'predicting using LBPH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using LBPH: 25%\n",
      "done in 340.987469912s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0 \n",
    "# recognizer_LBPH.train(train_X,np.array(train_Y))\n",
    "\n",
    "# for i, image in enumerate(prediction_data):\n",
    "\n",
    "#     pred, conf = recognizer_LBPH.predict(image)\n",
    "\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using LBPH: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using Fisher\n"
     ]
    }
   ],
   "source": [
    "print 'predicting using Fisher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "correct = 0\n",
    "incorrect = 0 \n",
    "recognizer_Fisher.train(train_X,np.array(train_Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, image in enumerate(prediction_data):\n",
    "\n",
    "    #detect using different classifiers\n",
    "    face = face_alt.detectMultiScale(image, **settings)\n",
    "    face2 = face_default.detectMultiScale(image, **settings)\n",
    "    face3 = face_profile.detectMultiScale(image, **settings)\n",
    "\n",
    "    #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face2) == 1:\n",
    "        facefeatures = face2\n",
    "    elif len(face3) == 1:\n",
    "        facefeatures = face3\n",
    "    else:\n",
    "        facefeatures = \"\"\n",
    "        num_not_detect = num_not_detect + 1\n",
    "\n",
    "    for (x, y, w, h) in facefeatures:\n",
    "        num_detect = num_detect + 1\n",
    "        test_X.append(image[y: y + h, x: x + w])\n",
    "        test_Y.append(prediction_labels[j])\n",
    "        cv2.imshow(\"Adding faces to testing set...\", image[y: y + h, x: x + w])\n",
    "        #cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(test_X):\n",
    "    pred, conf = recognizer_Fisher.predict(image)\n",
    "\n",
    "    if pred == test_Y[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "print 'accuracy using Fisher: {}%'.format((100*correct)/(correct + incorrect))\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using Eigen\n"
     ]
    }
   ],
   "source": [
    "print 'predicting using Eigen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using Eigen: 22%\n",
      "done in 2595.12101412s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# t0 = time.time()\n",
    "# correct = 0\n",
    "# incorrect = 0 \n",
    "# recognizer_Eigen.train(train_X,np.array(train_Y))\n",
    "# for i, image in enumerate(prediction_data):\n",
    "\n",
    "#     pred, conf = recognizer_Eigen.predict(image)\n",
    "\n",
    "#     if pred == prediction_labels[i]:\n",
    "#         correct += 1\n",
    "#     else:\n",
    "#         incorrect += 1\n",
    "# print 'accuracy using Eigen: {}%'.format((100*correct)/(correct + incorrect))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
