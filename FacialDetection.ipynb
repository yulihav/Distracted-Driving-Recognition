{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detecting faces from training data\n",
      "detected 2142 faces, out of 4387 (0.49)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pdb as pdb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Different recognizers\n",
    "recognizer_LBPH = cv2.face.createLBPHFaceRecognizer()\n",
    "recognizer_Fisher = cv2.face.createFisherFaceRecognizer()\n",
    "recognizer_Eigen = cv2.face.createEigenFaceRecognizer()\n",
    "\n",
    "# haar cascades for recognizing different angles\n",
    "cascade_paths = ['haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_default.xml', 'haarcascade_profileface.xml']\n",
    "\n",
    "face_alt = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "face_default = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "face_profile = cv2.CascadeClassifier(\"haarcascade_profileface.xml\")\n",
    "\n",
    "settings = {\n",
    "    'minNeighbors': 2, \n",
    "    'minSize': (40,40)\n",
    "}\n",
    "\n",
    "\n",
    "train = pd.read_csv('driver_imgs_list.csv')\n",
    "mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "train = train[mask]\n",
    "#train = train[0:500]\n",
    "\n",
    "predict_images = []\n",
    "\n",
    "scaled_size = (100,75)\n",
    "for i, image in train.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    predict_images.append(predict_image)\n",
    "    \n",
    "images, predict_images, labels, predict_labels = train_test_split( predict_images, train['classname'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Extract relevant data\n",
    "training_data = images\n",
    "training_labels = labels\n",
    "prediction_data = predict_images\n",
    "prediction_labels = predict_labels\n",
    "\n",
    "training_labels = map(lambda each:int(each.strip(\"c\")), training_labels)\n",
    "prediction_labels = map(lambda each:int(each.strip(\"c\")), prediction_labels)\n",
    "\n",
    "train_X=[]\n",
    "train_Y=[]\n",
    "test_X=[]\n",
    "test_Y=[]\n",
    "\n",
    "num_detect = 0\n",
    "num_not_detect = 0\n",
    "\n",
    "print 'detecting faces from training data'\n",
    "t0 = time()\n",
    "for j, image in enumerate(training_data):\n",
    "\n",
    "    #detect using different classifiers\n",
    "    face = face_alt.detectMultiScale(image, **settings)\n",
    "    face2 = face_default.detectMultiScale(image, **settings)\n",
    "    face3 = face_profile.detectMultiScale(image, **settings)\n",
    "\n",
    "    #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face2) == 1:\n",
    "        facefeatures = face2\n",
    "    elif len(face3) == 1:\n",
    "        facefeatures = face3\n",
    "    else:\n",
    "        facefeatures = \"\"\n",
    "        num_not_detect = num_not_detect + 1\n",
    "\n",
    "    for (x, y, w, h) in facefeatures:\n",
    "        num_detect = num_detect + 1\n",
    "        train_X.append(image)#[y: y + h, x: x + w])\n",
    "        train_Y.append(training_labels[j])\n",
    "        cv2.imshow(\"Adding faces to traning set...\", image[y: y + h, x: x + w])\n",
    "        #cv2.waitKey(100)\n",
    "\n",
    "percentage = num_detect/float((num_detect + num_not_detect))\n",
    "print 'detected {} faces, out of {} ({:0.2f})'.format(num_detect, num_detect + num_not_detect, percentage)\n",
    "print(\"done in {}s\".format(time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'predicting using LBPH'\n",
    "t0 = time()\n",
    "correct = 0\n",
    "incorrect = 0 \n",
    "mis=[0,0,0,0,0,0,0]\n",
    "recognizer_LBPH.train(train_X,np.array(train_Y))\n",
    "\n",
    "for i, image in enumerate(prediction_data):\n",
    "\n",
    "    pred, conf = recognizer_LBPH.predict(image)\n",
    "\n",
    "    if pred == prediction_labels[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        #mis[prediction_labels[i]] += 1\n",
    "        cv2.imwrite(\"difficult\\\\%s_%s_%s.jpg\" %(prediction_labels[i], pred, i), image) #<-- this one is new\n",
    "print 'accuracy using LBPH: {}%'.format((100*correct)/(correct + incorrect))\n",
    "print(\"done in {}s\".format(time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'predicting using Fisher'\n",
    "t0 = time()\n",
    "correct = 0\n",
    "incorrect = 0 \n",
    "recognizer_Fisher.train(train_X,np.array(train_Y))\n",
    "\n",
    "for i, image in enumerate(prediction_data):\n",
    "    pred, conf = recognizer_Fisher.predict(image)\n",
    "\n",
    "    if pred == prediction_labels[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "print 'accuracy using Fisher: {}%'.format((100*correct)/(correct + incorrect))\n",
    "print(\"done in {}s\".format(time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print 'predicting using Eigen'\n",
    "t0 = time()\n",
    "correct = 0\n",
    "incorrect = 0 \n",
    "recognizer_Eigen.train(train_X,np.array(train_Y))\n",
    "for i, image in enumerate(prediction_data):\n",
    "\n",
    "    pred, conf = recognizer_Eigen.predict(image)\n",
    "\n",
    "    if pred == prediction_labels[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "print 'accuracy using Eigen: {}%'.format((100*correct)/(correct + incorrect))\n",
    "print(\"done in {}s\".format(time() - t0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
