{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pdb as pdb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "settings = {\n",
    "    'minNeighbors': 2, \n",
    "    'minSize': (40,40)\n",
    "}\n",
    "image_list = pd.read_csv('driver_imgs_list.csv')\n",
    "train_subject_subset = image_list.subject.value_counts()[-9:].index.values\n",
    "test_subject_subset = image_list.subject.value_counts()[:-9].index.values\n",
    "train = image_list[image_list.subject.isin(train_subject_subset)].reset_index(drop=True)\n",
    "test = image_list[image_list.subject.isin(test_subject_subset)].reset_index(drop=True)\n",
    "\n",
    "#take 25% of the sets \n",
    "mask = np.random.choice([False, True], len(train), p=[0.75, 0.25])\n",
    "train = train[mask]\n",
    "mask = np.random.choice([False, True], len(test), p=[0.75, 0.25])\n",
    "test = test[mask]\n",
    "print 'done getting train/test sets'\n",
    "print 'getting images from paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "predict_images = []\n",
    "labels = [] \n",
    "predict_labels = []\n",
    "\n",
    "t0 = time.time()\n",
    "scaled_size = (200,150)\n",
    "\n",
    "for i, image in train.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    images.append(image.flatten())\n",
    "    labels.append(train['classname'][i])\n",
    "    \n",
    "for i, image in test.iterrows():\n",
    "    image_path = './train/' + image.classname + '/' + image.img\n",
    "    predict_image_pil = Image.open(image_path).convert('L') #greyscale\n",
    "    predict_image_pil.thumbnail(scaled_size, Image.ANTIALIAS) #resize\n",
    "    predict_image = np.array(predict_image_pil, 'uint8') #to array\n",
    "    predict_images.append(predict_image.flatten())\n",
    "    predict_labels.append(test['classname'][i])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract relevant data\n",
    "training_data = images\n",
    "training_labels = labels\n",
    "prediction_data = predict_images\n",
    "prediction_labels = predict_labels\n",
    "\n",
    "training_labels = map(lambda each:int(each.strip(\"c\")), training_labels)\n",
    "prediction_labels = map(lambda each:int(each.strip(\"c\")), prediction_labels)\n",
    "\n",
    "training_data = map(lambda each:each.flatten(), training_data)\n",
    "prediction_data = map(lambda each:each.flatten(), prediction_data)\n",
    "\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "print (\"training classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# import numpy\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# t0 = time.time()\n",
    "# model = xgb.XGBClassifier()\n",
    "# X = numpy.array(training_data)\n",
    "# model.fit(X, training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X = numpy.array(prediction_data)\n",
    "# pred = model.predict(X)\n",
    "# correct = np.sum(pred == prediction_labels)\n",
    "# print 'accuracy using XGBoost: {} / {} %'.format(correct, len(prediction_labels))\n",
    "# print(\"done in {}s\".format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self, num_boost_round=10, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'multi:softprob'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        self.label2num = {label: i for i, label in enumerate(sorted(set(y)))}\n",
    "        dtrain = xgb.DMatrix(X, label=[self.label2num[label] for label in y])\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    " \n",
    "    def predict(self, X):\n",
    "        num2label = {i: label for label, i in self.label2num.items()}\n",
    "        Y = self.predict_proba(X)\n",
    "        y = np.argmax(Y, axis=1)\n",
    "        return np.array([num2label[i] for i in y])\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict_proba(X)\n",
    "        return 1 / logloss(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "def logloss(y_true, Y_pred):\n",
    "    label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "    return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "clf = XGBoostClassifier(\n",
    "        eval_metric = 'auc',\n",
    "        num_class = 10,\n",
    "        eta = 0.1,\n",
    "        num_boost_round = 80,\n",
    "        max_depth = 10,\n",
    "        subsample = 0.5,\n",
    "        colsample_bytree = 1.0,\n",
    "        )\n",
    "parameters = {\n",
    "    'num_boost_round': [100, 250, 500],\n",
    "    'eta': [0.05, 0.1, 0.3],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.9, 1.0],\n",
    "    'colsample_bytree': [0.6,0.9, 1.0],\n",
    "}\n",
    "t0 = time.time()\n",
    "clf = GridSearchCV(clf, parameters, n_jobs=-1, cv=2)\n",
    "\n",
    "X = numpy.array(training_data)\n",
    "clf.fit(training_data, training_labels)\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print(score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "pred = clf.predict(prediction_data)\n",
    "correct = np.sum(pred == prediction_labels)\n",
    "print 'accuracy using XGBoost w/ grid search: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {}s\".format(time.time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using XGBoost: 916 / 4067 %\n",
      "done in 201.191013098 sec\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "param = {'max_depth':15, 'eta':0.2, 'objective':'multi:softmax', 'num_class':10}\n",
    "num_round = 5\n",
    "         \n",
    "xg_train = xgb.DMatrix( training_data, label=training_labels)\n",
    "xg_test = xgb.DMatrix(prediction_data, label=prediction_labels)\n",
    "         \n",
    "bst = xgb.train(param, xg_train, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(xg_test)\n",
    "\n",
    "\n",
    "# training_data = numpy.array(training_data)\n",
    "# clf.fit(training_data, training_labels)\n",
    "\n",
    "# prediction_data = numpy.array(prediction_data)\n",
    "# pred = clf.predict(prediction_data)\n",
    "correct = np.sum(preds == prediction_labels)\n",
    "print 'accuracy using XGBoost: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {} sec\".format(time.time() - t0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using XGBoost: 991 / 4067 %\n",
      "done in 215.162302971 sec\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "param = {'max_depth':1, 'eta':0.2, 'objective':'multi:softmax', 'num_class':10}\n",
    "num_round = 20\n",
    "         \n",
    "xg_train = xgb.DMatrix( training_data, label=training_labels)\n",
    "xg_test = xgb.DMatrix(prediction_data, label=prediction_labels)\n",
    "         \n",
    "bst = xgb.train(param, xg_train, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(xg_test)\n",
    "\n",
    "\n",
    "# training_data = numpy.array(training_data)\n",
    "# clf.fit(training_data, training_labels)\n",
    "\n",
    "# prediction_data = numpy.array(prediction_data)\n",
    "# pred = clf.predict(prediction_data)\n",
    "correct = np.sum(preds == prediction_labels)\n",
    "print 'accuracy using XGBoost: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {} sec\".format(time.time() - t0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using XGBoost: 944 / 4067 %\n",
      "done in 199.12429285 sec\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.3, 'objective':'multi:softmax', 'num_class':10}\n",
    "num_round = 5\n",
    "         \n",
    "xg_train = xgb.DMatrix( training_data, label=training_labels)\n",
    "xg_test = xgb.DMatrix(prediction_data, label=prediction_labels)\n",
    "         \n",
    "bst = xgb.train(param, xg_train, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(xg_test)\n",
    "\n",
    "\n",
    "# training_data = numpy.array(training_data)\n",
    "# clf.fit(training_data, training_labels)\n",
    "\n",
    "# prediction_data = numpy.array(prediction_data)\n",
    "# pred = clf.predict(prediction_data)\n",
    "correct = np.sum(preds == prediction_labels)\n",
    "print 'accuracy using XGBoost: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {} sec\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using XGBoost: 807 / 4067 %\n",
      "done in 229.05040288 sec\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "param = {'max_depth':10, 'eta':0.1, 'objective':'multi:softmax', 'num_class':10}\n",
    "num_round = 5\n",
    "         \n",
    "xg_train = xgb.DMatrix( training_data, label=training_labels)\n",
    "xg_test = xgb.DMatrix(prediction_data, label=prediction_labels)\n",
    "         \n",
    "bst = xgb.train(param, xg_train, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(xg_test)\n",
    "\n",
    "\n",
    "# training_data = numpy.array(training_data)\n",
    "# clf.fit(training_data, training_labels)\n",
    "\n",
    "# prediction_data = numpy.array(prediction_data)\n",
    "# pred = clf.predict(prediction_data)\n",
    "correct = np.sum(preds == prediction_labels)\n",
    "print 'accuracy using XGBoost: {} / {} %'.format(correct, len(prediction_labels))\n",
    "print(\"done in {} sec\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
